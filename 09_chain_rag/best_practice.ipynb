{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cfba1db7",
   "metadata": {},
   "source": [
    "# Best Practice"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c04dd032",
   "metadata": {},
   "source": [
    "## 0. DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a6dec85e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_community.document_loaders import PyPDFLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "83272a19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87\n"
     ]
    }
   ],
   "source": [
    "embedding = OpenAIEmbeddings(model='text-embedding-3-small')\n",
    "\n",
    "samsung_vision_2025_path = '../data/Samsung_Electronics_Sustainability_Report_2025_KOR.pdf'\n",
    "docs_2025 = PyPDFLoader(samsung_vision_2025_path).load()\n",
    "\n",
    "print(len(docs_2025))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "aca1817a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "237\n"
     ]
    }
   ],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=100)\n",
    "chunks_2025 = text_splitter.split_documents(docs_2025)\n",
    "\n",
    "print(len(chunks_2025))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee565e3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "collection_name = 'best_data'\n",
    "db_path = '../vectorstore/best_db'\n",
    "\n",
    "# db save\n",
    "db_2025 = Chroma.from_documents(\n",
    "    documents=chunks_2025, \n",
    "    collection_name=collection_name, \n",
    "    persist_directory=db_path, \n",
    "    embedding=embedding\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ecc7b75",
   "metadata": {},
   "source": [
    "## 1. RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "79ea97f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.runnables import RunnablePassthrough, RunnableLambda\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd5b8b3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# db load\n",
    "vector_db = Chroma(\n",
    "    persist_directory = db_path,\n",
    "    collection_name = collection_name,\n",
    "    embedding_function = embedding\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "091fbbb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_retriever = vector_db.as_retriever(\n",
    "    search_type = 'similarity',\n",
    "    search_kwargs = {\n",
    "        'k': 30\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f428df13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reranker\n",
    "\n",
    "from langchain_community.cross_encoders.huggingface import HuggingFaceCrossEncoder\n",
    "from langchain.retrievers.document_compressors import CrossEncoderReranker\n",
    "\n",
    "hf_ce = HuggingFaceCrossEncoder(\n",
    "    model_name = 'cross-encoder/ms-marco-MiniLM-L6-v2',\n",
    "    model_kwargs = {\n",
    "        'device' : 'cuda',\n",
    "        'max_length' : 512\n",
    "    }\n",
    ")\n",
    "\n",
    "reranker = CrossEncoderReranker(\n",
    "    model = hf_ce,\n",
    "    top_n = 10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "093fee1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.retrievers import ContextualCompressionRetriever\n",
    "\n",
    "com_retriever = ContextualCompressionRetriever(\n",
    "    base_retriever = sim_retriever,\n",
    "    base_compressor = reranker\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f761d32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reorder\n",
    "\n",
    "from langchain_community.document_transformers import LongContextReorder\n",
    "\n",
    "reorder  = LongContextReorder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "19f6c538",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_docs(docs):\n",
    "    \n",
    "    result = []\n",
    "    \n",
    "    for doc in docs:\n",
    "        result.append(doc.page_content.strip())\n",
    "    \n",
    "    return '\\n\\n---\\n\\n'.join(result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c56dd0b6",
   "metadata": {},
   "source": [
    "## 2. CHAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "54bab752",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    ('system', \"\"\"\n",
    "    주어진 컨텍스트만 근거로 간결하고 정확하게 답하도록 해라.\n",
    "    # Context\n",
    "    {context}\n",
    "    \"\"\"),\n",
    "    ('human', '{question}')\n",
    "])\n",
    "\n",
    "model = ChatOpenAI(\n",
    "    model='gpt-4.1-mini',\n",
    "    temperature=0\n",
    ")\n",
    "\n",
    "output_parser = StrOutputParser()\n",
    "\n",
    "llm_chain = prompt | model | output_parser"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "965814e6",
   "metadata": {},
   "source": [
    "## 3. TOTAL(RAG + CHAIN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "0deea998",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'삼성전자는 인재와 기술을 바탕으로 최고의 제품과 서비스를 창출하여 인류사회에 공헌한다는 경영철학 아래, 기술 리더십으로 재도약의 기반을 다지고 새로운 영역에서 미래 성장동력을 확보해 나갈 계획입니다. 또한, 2025년까지 사회공헌 분야에서 청년 소프트웨어 인재 양성과 자립 준비 청년 지원을 확대하며, 환경 분야에서는 DX부문 2030년, DS부문 2050년 탄소중립 달성을 목표로 재생에너지 전환과 자원순환 극대화에 노력할 예정입니다.'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 중간 단계의 가변성을 위해서 람다를 적극적으로 활용\n",
    "total_chain1 = (\n",
    "    {\n",
    "    'docs': RunnableLambda(lambda x: com_retriever.invoke(x['question'])),\n",
    "    'question': RunnablePassthrough()    \n",
    "    }\n",
    "    | RunnableLambda(lambda x: {\n",
    "        'context': format_docs(reorder.transform_documents(x['docs'])),  \n",
    "        'question': x['question']\n",
    "    })\n",
    "    | llm_chain\n",
    ")\n",
    "\n",
    "total_chain1.invoke({\n",
    "    'question' : '삼성전자의 미래 사업 계획'\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "4ced7e0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"삼성전자는 인재와 기술을 바탕으로 최고의 제품과 서비스를 창출하여 인류사회에 공헌한다는 경영철학 아래, 기술 리더십으로 재도약의 기반을 다지고 새로운 영역에서 미래 성장동력을 확보할 계획입니다. 또한, 2025년에는 '삼성 청년SW·AI아카데미' 교육 대상을 마이스터고 졸업생까지 확대하고, '삼성 희망디딤돌' 인천센터를 추가 설립하여 더 많은 청년을 지원할 예정입니다. 환경 분야에서는 DX부문이 2030년 탄소중립 달성을 목표로 재생에너지 전환과 에너지 효율 개선에 집중하며, DS부문은 2050년 탄소중립을 목표로 하고 있습니다.\""
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_chain2 = (\n",
    "    {\n",
    "    'context': RunnableLambda(lambda x: x['question']) | com_retriever | reorder.transform_documents | format_docs,\n",
    "    'question': RunnablePassthrough()\n",
    "    } \n",
    "    | llm_chain\n",
    ")\n",
    "\n",
    "total_chain2.invoke({\n",
    "    'question' : '삼성전자의 미래 사업 계획'\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a4d594e",
   "metadata": {},
   "source": [
    "## 4. TOTAL(+Multi Input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59f519db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['context', 'pro', 'question'], input_types={}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context'], input_types={}, partial_variables={}, template='\\n    주어진 컨텍스트만 근거로 간결하고 정확하게 답하도록 해라.\\n    # Context\\n    {context}\\n    '), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['pro', 'question'], input_types={}, partial_variables={}, template='{pro}의 스타일에 맞게 {question}'), additional_kwargs={})])\n",
       "| ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x00000206CA731250>, async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x000002067624FD90>, root_client=<openai.OpenAI object at 0x0000020682721890>, root_async_client=<openai.AsyncOpenAI object at 0x00000206CA732DD0>, model_name='gpt-4.1-mini', temperature=0.0, model_kwargs={}, openai_api_key=SecretStr('**********'), stream_usage=True)\n",
       "| StrOutputParser()"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    ('system', \"\"\"\n",
    "    주어진 컨텍스트만 근거로 간결하고 정확하게 답하도록 해라.\n",
    "    # Context\n",
    "    {context}\n",
    "    \"\"\"),\n",
    "    ('human', '{pro}의 스타일에 맞게 {question}')\n",
    "])\n",
    "\n",
    "model = ChatOpenAI(\n",
    "    model='gpt-4.1-mini',\n",
    "    temperature=0\n",
    ")\n",
    "\n",
    "output_parser = StrOutputParser()\n",
    "\n",
    "multi_llm_chain = prompt | model | output_parser\n",
    "multi_llm_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "476c2211",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'삼성전자는 앞으로 모든 청소년이 좋은 교육을 받을 수 있도록 도와줄 거예요. 예를 들어, 컴퓨터와 인공지능을 배우는 특별한 학교를 운영하고, 중학생들이 꿈을 찾고 공부할 수 있게 멘토와 함께 공부하는 프로그램도 있어요. 또, 작은 회사와 새로운 아이디어를 가진 스타트업도 도와서 더 멋진 기술과 제품이 나오도록 할 계획이에요. 이렇게 삼성은 모두가 더 밝은 미래를 만들 수 있도록 힘쓰고 있어요!'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_chain = (\n",
    "    {\n",
    "        \"context\" :  RunnableLambda(lambda x: x['question']) | com_retriever | format_docs,\n",
    "        \"question\" : RunnableLambda(lambda x: x['question']),\n",
    "        \"pro\" : RunnableLambda(lambda x: x['pro'])\n",
    "    }\n",
    "    | multi_llm_chain\n",
    ")\n",
    "\n",
    "total_chain.invoke({\n",
    "    'question' : '삼성의 미래 계획은 어떻게 되나요?',\n",
    "    \"pro\" : '초등학생'\n",
    "})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain-basic",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
