{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "70fb5de0",
   "metadata": {},
   "source": [
    "# Summary History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "99a70ed0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'LANGCHAIN-BASIC'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "os.environ[\"LANGSMITH_PROJECT\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e6133eb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "model = ChatOpenAI(\n",
    "    temperature=0.1,\n",
    "    model='gpt-4.1-mini',\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fed2e440",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, Tuple\n",
    "from langchain_core.chat_history import InMemoryChatMessageHistory, BaseChatMessageHistory\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "from langchain_core.runnables.utils import ConfigurableFieldSpec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b39db3c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"\"\"\n",
    "추석 덕담을 나누는 상황이야 답변을 해줘\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "20e62e75",
   "metadata": {},
   "outputs": [],
   "source": [
    "stores : Dict[Tuple[str, str], InMemoryChatMessageHistory] = {}\n",
    "\n",
    "def get_session_history(session_id: str, conversation_id: str) -> BaseChatMessageHistory:\n",
    "    \n",
    "    key = (session_id, conversation_id)\n",
    "    \n",
    "    if key not in stores:\n",
    "        stores[key] = InMemoryChatMessageHistory()\n",
    "        \n",
    "    return stores[key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e24c6d9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 대화내용 요약 chain\n",
    "summaries : Dict[Tuple[str, str], str] = {}\n",
    "\n",
    "summaries_prompt = ChatPromptTemplate.from_messages([\n",
    "    '다음 대화 내용을 5단어로 요약해. 불필요한 내용은 제외!\\n 대화내용 : {content_text}'   \n",
    "])\n",
    "\n",
    "summaries_chain = summaries_prompt | model | StrOutputParser()\n",
    "\n",
    "# threshold만큼 요약\n",
    "def maybe_summarize(session_id: str, conversation_id: str, threshold: int=8):\n",
    "    \n",
    "    store = get_session_history(session_id, conversation_id)\n",
    "    \n",
    "    if len(store.messages) > threshold:\n",
    "        \n",
    "        content_text = \"\" # 지금까지 대화내용을 합친 글자\n",
    "        for i in store.messages:\n",
    "            content_text += i.content + '\\n'\n",
    "            \n",
    "        summaries[(session_id, conversation_id)] = summaries_chain.invoke({'content_text' : content_text})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3057e2db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['history', 'question', 'summary'], input_types={'history': list[typing.Annotated[typing.Union[typing.Annotated[langchain_core.messages.ai.AIMessage, Tag(tag='ai')], typing.Annotated[langchain_core.messages.human.HumanMessage, Tag(tag='human')], typing.Annotated[langchain_core.messages.chat.ChatMessage, Tag(tag='chat')], typing.Annotated[langchain_core.messages.system.SystemMessage, Tag(tag='system')], typing.Annotated[langchain_core.messages.function.FunctionMessage, Tag(tag='function')], typing.Annotated[langchain_core.messages.tool.ToolMessage, Tag(tag='tool')], typing.Annotated[langchain_core.messages.ai.AIMessageChunk, Tag(tag='AIMessageChunk')], typing.Annotated[langchain_core.messages.human.HumanMessageChunk, Tag(tag='HumanMessageChunk')], typing.Annotated[langchain_core.messages.chat.ChatMessageChunk, Tag(tag='ChatMessageChunk')], typing.Annotated[langchain_core.messages.system.SystemMessageChunk, Tag(tag='SystemMessageChunk')], typing.Annotated[langchain_core.messages.function.FunctionMessageChunk, Tag(tag='FunctionMessageChunk')], typing.Annotated[langchain_core.messages.tool.ToolMessageChunk, Tag(tag='ToolMessageChunk')]], FieldInfo(annotation=NoneType, required=True, discriminator=Discriminator(discriminator=<function _get_type at 0x0000025FCB612FC0>, custom_error_type=None, custom_error_message=None, custom_error_context=None))]]}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='\\n추석 덕담을 나누는 상황이야 답변을 해줘\\n'), additional_kwargs={}), SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=['summary'], input_types={}, partial_variables={}, template='과거 요약:\\n{summary}'), additional_kwargs={}), MessagesPlaceholder(variable_name='history'), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['question'], input_types={}, partial_variables={}, template='{question}'), additional_kwargs={})])\n",
       "| ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x0000025FCCC08310>, async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x0000025FCD06EB50>, root_client=<openai.OpenAI object at 0x0000025FCCBE6E90>, root_async_client=<openai.AsyncOpenAI object at 0x0000025FCD06E650>, model_name='gpt-4.1-mini', temperature=0.1, model_kwargs={}, openai_api_key=SecretStr('**********'))\n",
       "| StrOutputParser()"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_template = ChatPromptTemplate.from_messages([\n",
    "    ('system', system_prompt), # system prompt가 여러개면 하나로 합쳐서 적용됨\n",
    "    ('system', '과거 요약:\\n{summary}'),\n",
    "    MessagesPlaceholder(variable_name='history'),\n",
    "    ('user', '{question}')\n",
    "])\n",
    "\n",
    "chain = prompt_template | model | StrOutputParser()\n",
    "chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d2cf5b4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with_summary_chain = RunnableWithMessageHistory(\n",
    "    chain,\n",
    "    get_session_history,\n",
    "    input_messages_key='question',\n",
    "    history_messages_key='history',\n",
    "    history_factory_config=[\n",
    "        ConfigurableFieldSpec(\n",
    "            id=\"session_id\",\n",
    "            annotation=str,\n",
    "            name=\"User ID\",\n",
    "            description=\"Unique identifier for the user.\",\n",
    "            default=\"\",\n",
    "            is_shared=True,\n",
    "        ),\n",
    "        ConfigurableFieldSpec(\n",
    "            id=\"conversation_id\",\n",
    "            annotation=str,\n",
    "            name=\"Conversation ID\",\n",
    "            description=\"Unique identifier for the conversation.\",\n",
    "            default=\"\",\n",
    "            is_shared=True,\n",
    "        ),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a45c19af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ask(question: str, session_id: str, conversation_id: str) -> str:\n",
    "    \n",
    "    maybe_summarize(session_id, conversation_id)\n",
    "    config = {'configurable': {'session_id': session_id, 'conversation_id': conversation_id}}\n",
    "    \n",
    "    return with_summary_chain.invoke(\n",
    "        {'question': question, \n",
    "        'summary': summaries.get((session_id, conversation_id), 'empty')},\n",
    "        config\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75e4f30f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "감사합니다! 가족 모두 건강하고 행복한 한가위 보내시길 바랍니다. 풍성한 명절 되세요!\n"
     ]
    }
   ],
   "source": [
    "ask(\"오래오래 건강하세요\", \"walker0625\", \"conv-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65f7a064",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "고마워요! 당신도 하시는 모든 일마다 좋은 결과 있길 진심으로 응원할게요. 행복한 추석 보내세요!\n"
     ]
    }
   ],
   "source": [
    "ask(\"하는 일 다 잘되렴\", \"walker0625\", \"conv-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46505f2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "감사합니다! 새해에는 부자 되시고, 원하는 모든 일 이루시길 바랍니다. 즐거운 추석 보내세요!\n"
     ]
    }
   ],
   "source": [
    "ask(\"새해에는 돈 많이 벌으렴\", \"walker0625\", \"conv-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "867bc727",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정말 따뜻한 덕담이에요! 새해에는 좋은 일만 가득하고, 건강과 행복이 늘 함께하길 진심으로 기원합니다. 행복한 추석 보내세요!\n"
     ]
    }
   ],
   "source": [
    "ask(\"새해엔 나쁜 일이 없길바래\", \"walker0625\", \"conv-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "32e2fe98",
   "metadata": {},
   "outputs": [],
   "source": [
    "summaries.get((\"walker0625\", \"conv-1\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "146c28e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='오래오래 건강하세요', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='감사합니다! 가족 모두 건강하고 행복한 한가위 보내시길 바랍니다. 풍성한 명절 되세요!', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='하는 일 다 잘되렴', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='고마워요! 당신도 하시는 모든 일마다 좋은 결과 있길 진심으로 응원할게요. 행복한 추석 보내세요!', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='새해에는 돈 많이 벌으렴', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='감사합니다! 새해에는 부자 되시고, 원하는 모든 일 이루시길 바랍니다. 즐거운 추석 보내세요!', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='새해엔 나쁜 일이 없길바래', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='정말 따뜻한 덕담이에요! 새해에는 좋은 일만 가득하고, 건강과 행복이 늘 함께하길 진심으로 기원합니다. 행복한 추석 보내세요!', additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stores[(\"walker0625\", \"conv-1\")].messages"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain-basic",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
