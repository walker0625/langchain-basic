{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "752d5885",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'LANGCHAIN-BASIC'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "import os\n",
    "\n",
    "os.environ[\"LANGSMITH_PROJECT\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3694ead7",
   "metadata": {},
   "source": [
    "### 1. LCEL 기본 구조(Lang Chain Expression Language)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "681b97fe",
   "metadata": {},
   "source": [
    "### 1) 프롬프트 템플릿"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "68d8ed42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['kind', 'skill'], input_types={}, partial_variables={}, template='{skill}의 가장 중요한 점을 생각하고, {kind} 개발자에게 중요한 점 3가지를 알려줘')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "template = '{skill}의 가장 중요한 점을 생각하고, {kind} 개발자에게 중요한 점 3가지를 알려줘'\n",
    "\n",
    "prompt_template = PromptTemplate.from_template(template)\n",
    "prompt_template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eef69f7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt_template.format(skill='langchain')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9348ace2",
   "metadata": {},
   "source": [
    "### 2) 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9c0fadc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "model = ChatOpenAI(\n",
    "    temperature=0.1,\n",
    "    model='gpt-4.1-mini',\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca4a3d84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['skill'], input_types={}, partial_variables={}, template='{skill}의 가장 중요한 점 3가지')\n",
       "| ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x0000026AF09CFB50>, async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x0000026AF0AE9590>, root_client=<openai.OpenAI object at 0x0000026AF05C8E90>, root_async_client=<openai.AsyncOpenAI object at 0x0000026AF0AE90D0>, model_name='gpt-4.1-mini', temperature=0.1, model_kwargs={}, openai_api_key=SecretStr('**********'))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain = prompt_template | model\n",
    "chain # input_variables를 확인해서 넣어줌"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7e4971d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LangChain의 가장 중요한 점 3가지는 다음과 같습니다:\n",
      "\n",
      "1. **언어 모델과의 통합 및 확장성**  \n",
      "   LangChain은 다양한 언어 모델(예: OpenAI GPT, Hugging Face 모델 등)과 쉽게 통합할 수 있도록 설계되어 있습니다. 이를 통해 사용자는 자신이 원하는 모델을 선택하고, 필요에 따라 커스텀 파이프라인을 구축할 수 있습니다.\n",
      "\n",
      "2. **체인(Chain) 기반의 작업 흐름 구성**  \n",
      "   LangChain은 여러 개의 언어 모델 호출, 데이터 처리, 외부 API 연동 등을 체인 형태로 연결하여 복잡한 작업 흐름을 쉽게 구성할 수 있게 해줍니다. 이를 통해 단순한 질의응답부터 복잡한 멀티스텝 작업까지 유연하게 처리할 수 있습니다.\n",
      "\n",
      "3. **데이터 연결 및 메모리 관리**  \n",
      "   LangChain은 외부 데이터 소스(예: 데이터베이스, 문서, 웹페이지 등)와 연결하여 언어 모델이 더 풍부한 정보를 바탕으로 응답할 수 있도록 지원합니다. 또한, 대화형 애플리케이션에서 상태를 유지하는 메모리 기능을 제공하여 자연스러운 대화 흐름을 구현할 수 있습니다.\n",
      "\n",
      "이 세 가지 요소가 LangChain을 활용한 언어 모델 기반 애플리케이션 개발의 핵심적인 강점입니다.\n"
     ]
    }
   ],
   "source": [
    "input = {'skill': 'langchain', 'kind' : 'ai agent'}\n",
    "\n",
    "answer = chain.invoke(input)\n",
    "print(answer.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ef2bd556",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='LangChain의 가장 중요한 점 3가지는 다음과 같습니다:\\n\\n1. **언어 모델과의 통합 및 확장성**  \\n   LangChain은 다양한 언어 모델(예: OpenAI GPT, Hugging Face 모델 등)과 쉽게 통합할 수 있도록 설계되어 있습니다. 이를 통해 사용자는 자신이 원하는 모델을 선택하고, 필요에 따라 커스텀 파이프라인을 구축할 수 있습니다.\\n\\n2. **체인(Chain) 기반의 작업 흐름 구성**  \\n   LangChain은 여러 개의 언어 모델 호출, 데이터 처리, 외부 API 연동 등을 체인 형태로 연결하여 복잡한 작업 흐름을 쉽게 구성할 수 있게 해줍니다. 이를 통해 단순한 질의응답부터 복잡한 멀티스텝 작업까지 유연하게 처리할 수 있습니다.\\n\\n3. **데이터 연결 및 메모리 관리**  \\n   LangChain은 외부 데이터 소스(예: 데이터베이스, 문서, 웹페이지 등)와 연결하여 언어 모델이 더 풍부한 정보를 바탕으로 응답할 수 있도록 지원합니다. 또한, 대화형 애플리케이션에서 상태를 유지하는 메모리 기능을 제공하여 자연스러운 대화 흐름을 구현할 수 있습니다.\\n\\n이 세 가지 요소가 LangChain을 활용한 언어 모델 기반 애플리케이션 개발의 핵심적인 강점입니다.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 303, 'prompt_tokens': 16, 'total_tokens': 319, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4.1-mini-2025-04-14', 'system_fingerprint': 'fp_4fce0778af', 'id': 'chatcmpl-CLKXamhV3H1tqet4TlXwrEmaotqSJ', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--f68b8fd8-670e-418d-9660-70b570de7570-0', usage_metadata={'input_tokens': 16, 'output_tokens': 303, 'total_tokens': 319, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9e1cc75",
   "metadata": {},
   "source": [
    "### 3) 출력양식 정의\n",
    "\n",
    "##### Stroutputparser : 단순 문자열 출력(줄바꿈, split)\n",
    "##### Jsonoutputparser\n",
    "##### PydanticOutputParser\n",
    "##### CommaSeperate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "58e73065",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LangChain의 가장 중요한 점은 **언어 모델(LLM)을 다양한 데이터 소스 및 도구와 효과적으로 연결하여 복잡한 작업을 자동화하고 확장 가능하게 만드는 프레임워크**라는 점입니다. 즉, 단순한 텍스트 생성에서 나아가, 외부 API 호출, 데이터베이스 쿼리, 사용자 인터랙션 등과 결합해 실질적인 AI 에이전트를 구현할 수 있도록 돕는다는 것입니다.\n",
      "\n",
      "AI 에이전트 개발자에게 중요한 점 3가지는 다음과 같습니다:\n",
      "\n",
      "1. **모듈화와 확장성 이해**  \n",
      "   LangChain은 프롬프트 템플릿, 체인(chains), 에이전트(agents), 메모리(memory) 등 여러 컴포넌트로 구성되어 있습니다. 각 컴포넌트를 적절히 조합하고 확장할 수 있어야 복잡한 워크플로우를 유연하게 설계할 수 있습니다.\n",
      "\n",
      "2. **외부 도구 및 데이터 소스 통합 능력**  \n",
      "   AI 에이전트는 단순한 텍스트 생성기를 넘어서서, API 호출, 데이터베이스 접근, 파일 시스템 조작 등 다양한 외부 리소스와 상호작용해야 합니다. LangChain의 도구(tool) 인터페이스와 에이전트 프레임워크를 활용해 이런 통합을 효과적으로 구현하는 것이 중요합니다.\n",
      "\n",
      "3. **프롬프트 엔지니어링과 컨텍스트 관리**  \n",
      "   좋은 결과를 위해서는 적절한 프롬프트 설계가 필수적이며, LangChain의 메모리 기능을 활용해 대화나 작업의 컨텍스트를 유지하는 것이 중요합니다. 이를 통해 에이전트가 더 자연스럽고 일관성 있는 응답을 생성할 수 있습니다.\n",
      "\n",
      "요약하면, LangChain을 잘 활용하려면 **구성요소의 이해와 조합, 외부 시스템과의 연동, 그리고 효과적인 프롬프트 및 컨텍스트 관리**가 핵심 역량입니다.\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "out_put_parser = StrOutputParser()\n",
    "\n",
    "chain = prompt_template | model | out_put_parser\n",
    "\n",
    "answer = chain.invoke({'skill': 'langchain', 'kind' : 'ai agent'})\n",
    "print(answer) # answer.content를 할 필요없이 바로 응답 확인\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2eb13e1",
   "metadata": {},
   "source": [
    "### 4) 다양한 chain 실행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "15b2a89d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['skill', 'year'], input_types={}, partial_variables={}, template='\\n최근 {year}년 간 {skill} 분야의 기술 발전에 대해서 알려줘\\n')\n",
       "| ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x0000025009705790>, async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x0000025009C1A890>, root_client=<openai.OpenAI object at 0x0000025009787A50>, root_async_client=<openai.AsyncOpenAI object at 0x0000025009C1A410>, model_name='gpt-4.1-mini', temperature=0.1, model_kwargs={}, openai_api_key=SecretStr('**********'))\n",
       "| StrOutputParser()"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# 프롬프트 템플릿 설정\n",
    "template = '''\n",
    "최근 {year}년 간 {skill} 분야의 기술 발전에 대해서 알려줘\n",
    "'''\n",
    "\n",
    "prompt_template = PromptTemplate.from_template(template)\n",
    "\n",
    "# 아웃풋 파서 설정\n",
    "out_put_parser = StrOutputParser()\n",
    "\n",
    "chain = prompt_template | model | out_put_parser\n",
    "chain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec1a0d6a",
   "metadata": {},
   "source": [
    "##### (1) batch 출력(잘 쓰진 않음)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea3d2775",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['최근 3년 간 RAG (Retrieval-Augmented Generation) 분야의 기술 발전은 매우 빠르게 이루어졌으며, 특히 대규모 언어 모델과 정보 검색 기술의 결합을 통해 자연어 처리(NLP) 및 생성 모델의 성능을 크게 향상시켰습니다. 주요 발전 내용을 요약하면 다음과 같습니다.\\n\\n1. **RAG 모델의 등장과 발전 (2020~2021년)**\\n   - 페이스북 AI(현 메타 AI)가 2020년에 발표한 RAG 모델은 사전 학습된 생성 모델과 외부 지식 베이스에서 정보를 검색하는 검색 모델을 결합한 최초의 대표적인 접근법입니다.\\n   - 이 모델은 검색된 문서들을 조건으로 하여 텍스트를 생성함으로써, 단순한 생성 모델보다 더 정확하고 사실 기반의 응답을 생성할 수 있음을 보여주었습니다.\\n   - 이후 다양한 변형 모델들이 등장하며, 검색 효율성 및 생성 품질을 개선하는 연구가 활발히 진행되었습니다.\\n\\n2. **대규모 언어 모델과의 통합**\\n   - GPT-3, PaLM, LLaMA 등 대규모 언어 모델들이 등장하면서, 이들을 RAG 프레임워크에 통합하는 시도가 늘어났습니다.\\n   - 특히, 대규모 언어 모델의 강력한 생성 능력과 외부 지식 검색의 결합으로, 더 정확하고 신뢰성 있는 답변 생성이 가능해졌습니다.\\n   - OpenAI의 ChatGPT와 같은 시스템도 내부적으로 RAG와 유사한 접근법을 활용하여 최신 정보에 접근하는 방식을 연구 중입니다.\\n\\n3. **효율적인 검색 및 인덱싱 기술 발전**\\n   - 벡터 검색(Vector Search) 기술이 크게 발전하여, 대규모 문서 집합에서 빠르고 정확한 관련 문서 검색이 가능해졌습니다.\\n   - FAISS, Annoy, HNSW 등의 라이브러리가 널리 사용되며, 이와 함께 문서 임베딩 품질 향상을 위한 다양한 사전학습 기법도 개발되었습니다.\\n   - 이로 인해 RAG 시스템의 실시간 응답 속도와 정확도가 크게 개선되었습니다.\\n\\n4. **멀티모달 RAG 및 도메인 특화 적용**\\n   - 텍스트뿐만 아니라 이미지, 음성 등 다양한 형태의 데이터를 검색하고 생성에 활용하는 멀티모달 RAG 연구가 진행되고 있습니다.\\n   - 의료, 법률, 금융 등 특정 도메인에 특화된 RAG 시스템 개발도 활발하여, 전문 지식 기반의 정확한 정보 제공이 가능해졌습니다.\\n\\n5. **오픈소스 및 상용화 확대**\\n   - Hugging Face, Meta AI, Google Research 등에서 다양한 오픈소스 RAG 구현체와 튜토리얼을 공개하여 연구 및 산업계에서의 접근성이 높아졌습니다.\\n   - 기업들은 고객 지원, 지식 관리, 챗봇 등 다양한 분야에 RAG 기술을 적용하여 상용화 사례가 증가하고 있습니다.\\n\\n요약하자면, 최근 3년간 RAG 분야는 대규모 언어 모델과 고성능 검색 기술의 결합을 통해 생성 모델의 정확성과 신뢰성을 크게 향상시키고 있으며, 멀티모달 확장과 도메인 특화 적용, 그리고 실시간 응답 성능 개선에 중점을 두고 빠르게 발전하고 있습니다.', '최근 3년 간 MCP (Microchannel Plate) 분야의 기술 발전에 대해 요약해 드리겠습니다. MCP는 주로 고감도 광검출기, 전자 증폭기, 우주 탐사 장비 등에서 사용되는 핵심 부품으로, 미세한 채널을 통해 전자를 증폭시키는 역할을 합니다.\\n\\n### 1. 소재 및 제조 기술의 발전\\n- **나노구조 및 신소재 적용**: 최근 MCP 제조에 있어 전통적인 유리 기반 소재 외에도 나노구조를 활용한 신소재가 도입되고 있습니다. 예를 들어, 탄소 나노튜브(CNT)나 그래핀을 활용한 MCP가 연구되어 전자 증폭 효율과 내구성을 크게 향상시키고 있습니다.\\n- **3D 프린팅 및 미세가공 기술**: 고해상도 3D 프린팅과 레이저 미세가공 기술을 통해 MCP의 채널 구조를 더욱 정밀하게 제작할 수 있게 되어, 성능과 신뢰성이 개선되고 있습니다.\\n\\n### 2. 성능 향상\\n- **고감도 및 저잡음 증폭**: 최신 MCP는 전자 증폭 배율이 크게 향상되었으며, 잡음 수준은 감소하여 더욱 정밀한 신호 검출이 가능해졌습니다. 이는 특히 우주 탐사 및 핵물리 실험에서 중요한 발전입니다.\\n- **고속 응답 및 내구성 강화**: MCP의 응답 속도가 빨라져 초고속 이벤트 검출에 적합해졌으며, 내구성도 개선되어 장기간 사용 시 성능 저하가 줄어들고 있습니다.\\n\\n### 3. 응용 분야 확대\\n- **우주 및 천문학 분야**: NASA, ESA 등 주요 우주 기관에서 MCP 기반 검출기를 우주 망원경, 우주 탐사선 등에 적용하여 우주 방사선 및 입자 검출 성능을 높이고 있습니다.\\n- **의료 영상 및 생명과학**: MCP 기술이 의료용 이미징 장비, 특히 PET(양전자 방출 단층촬영) 및 형광 이미징 분야에 적용되어 해상도와 감도가 향상되고 있습니다.\\n- **보안 및 산업 검사**: 고감도 광검출이 필요한 보안 스캐너, 비파괴 검사 장비에도 MCP 기술이 확대 적용되고 있습니다.\\n\\n### 4. 집적화 및 소형화\\n- MCP와 관련 전자회로의 집적화가 진행되어, 소형화된 고성능 검출기 개발이 가능해졌습니다. 이는 휴대용 장비나 드론, 소형 위성 등에 탑재할 수 있는 MCP 기반 센서 개발로 이어지고 있습니다.\\n\\n---\\n\\n요약하자면, 최근 3년 간 MCP 분야는 소재 혁신, 제조 정밀도 향상, 성능 개선, 그리고 다양한 응용 분야 확대를 중심으로 빠르게 발전하고 있습니다. 특히 나노소재 적용과 고속·고감도 증폭 기술이 두드러진 특징입니다. 필요하시면 특정 응용 분야나 기술에 대해 더 자세히 설명드릴 수 있습니다.']\n"
     ]
    }
   ],
   "source": [
    "response = chain.batch([{'skill' : 'rag', 'year' : 3}, {'skill' : 'mcp', 'year' : 3}]) # llm 서버에서 동시에 처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7d30aaa0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "최근 3년 간 RAG (Retrieval-Augmented Generation) 분야의 기술 발전은 매우 빠르게 이루어졌으며, 특히 대규모 언어 모델과 정보 검색 기술의 결합을 통해 자연어 처리(NLP) 및 생성 모델의 성능을 크게 향상시켰습니다. 주요 발전 내용을 요약하면 다음과 같습니다.\n",
      "\n",
      "1. **RAG 모델의 등장과 발전 (2020~2021년)**\n",
      "   - 페이스북 AI(현 메타 AI)가 2020년에 발표한 RAG 모델은 사전 학습된 생성 모델과 외부 지식 베이스에서 정보를 검색하는 검색 모델을 결합한 최초의 대표적인 접근법입니다.\n",
      "   - 이 모델은 검색된 문서들을 조건으로 하여 텍스트를 생성함으로써, 단순한 생성 모델보다 더 정확하고 사실 기반의 응답을 생성할 수 있음을 보여주었습니다.\n",
      "   - 이후 다양한 변형 모델들이 등장하며, 검색 효율성 및 생성 품질을 개선하는 연구가 활발히 진행되었습니다.\n",
      "\n",
      "2. **대규모 언어 모델과의 통합**\n",
      "   - GPT-3, PaLM, LLaMA 등 대규모 언어 모델들이 등장하면서, 이들을 RAG 프레임워크에 통합하는 시도가 늘어났습니다.\n",
      "   - 특히, 대규모 언어 모델의 강력한 생성 능력과 외부 지식 검색의 결합으로, 더 정확하고 신뢰성 있는 답변 생성이 가능해졌습니다.\n",
      "   - OpenAI의 ChatGPT와 같은 시스템도 내부적으로 RAG와 유사한 접근법을 활용하여 최신 정보에 접근하는 방식을 연구 중입니다.\n",
      "\n",
      "3. **효율적인 검색 및 인덱싱 기술 발전**\n",
      "   - 벡터 검색(Vector Search) 기술이 크게 발전하여, 대규모 문서 집합에서 빠르고 정확한 관련 문서 검색이 가능해졌습니다.\n",
      "   - FAISS, Annoy, HNSW 등의 라이브러리가 널리 사용되며, 이와 함께 문서 임베딩 품질 향상을 위한 다양한 사전학습 기법도 개발되었습니다.\n",
      "   - 이로 인해 RAG 시스템의 실시간 응답 속도와 정확도가 크게 개선되었습니다.\n",
      "\n",
      "4. **멀티모달 RAG 및 도메인 특화 적용**\n",
      "   - 텍스트뿐만 아니라 이미지, 음성 등 다양한 형태의 데이터를 검색하고 생성에 활용하는 멀티모달 RAG 연구가 진행되고 있습니다.\n",
      "   - 의료, 법률, 금융 등 특정 도메인에 특화된 RAG 시스템 개발도 활발하여, 전문 지식 기반의 정확한 정보 제공이 가능해졌습니다.\n",
      "\n",
      "5. **오픈소스 및 상용화 확대**\n",
      "   - Hugging Face, Meta AI, Google Research 등에서 다양한 오픈소스 RAG 구현체와 튜토리얼을 공개하여 연구 및 산업계에서의 접근성이 높아졌습니다.\n",
      "   - 기업들은 고객 지원, 지식 관리, 챗봇 등 다양한 분야에 RAG 기술을 적용하여 상용화 사례가 증가하고 있습니다.\n",
      "\n",
      "요약하자면, 최근 3년간 RAG 분야는 대규모 언어 모델과 고성능 검색 기술의 결합을 통해 생성 모델의 정확성과 신뢰성을 크게 향상시키고 있으며, 멀티모달 확장과 도메인 특화 적용, 그리고 실시간 응답 성능 개선에 중점을 두고 빠르게 발전하고 있습니다.\n",
      "최근 3년 간 MCP (Microchannel Plate) 분야의 기술 발전에 대해 요약해 드리겠습니다. MCP는 주로 고감도 광검출기, 전자 증폭기, 우주 탐사 장비 등에서 사용되는 핵심 부품으로, 미세한 채널을 통해 전자를 증폭시키는 역할을 합니다.\n",
      "\n",
      "### 1. 소재 및 제조 기술의 발전\n",
      "- **나노구조 및 신소재 적용**: 최근 MCP 제조에 있어 전통적인 유리 기반 소재 외에도 나노구조를 활용한 신소재가 도입되고 있습니다. 예를 들어, 탄소 나노튜브(CNT)나 그래핀을 활용한 MCP가 연구되어 전자 증폭 효율과 내구성을 크게 향상시키고 있습니다.\n",
      "- **3D 프린팅 및 미세가공 기술**: 고해상도 3D 프린팅과 레이저 미세가공 기술을 통해 MCP의 채널 구조를 더욱 정밀하게 제작할 수 있게 되어, 성능과 신뢰성이 개선되고 있습니다.\n",
      "\n",
      "### 2. 성능 향상\n",
      "- **고감도 및 저잡음 증폭**: 최신 MCP는 전자 증폭 배율이 크게 향상되었으며, 잡음 수준은 감소하여 더욱 정밀한 신호 검출이 가능해졌습니다. 이는 특히 우주 탐사 및 핵물리 실험에서 중요한 발전입니다.\n",
      "- **고속 응답 및 내구성 강화**: MCP의 응답 속도가 빨라져 초고속 이벤트 검출에 적합해졌으며, 내구성도 개선되어 장기간 사용 시 성능 저하가 줄어들고 있습니다.\n",
      "\n",
      "### 3. 응용 분야 확대\n",
      "- **우주 및 천문학 분야**: NASA, ESA 등 주요 우주 기관에서 MCP 기반 검출기를 우주 망원경, 우주 탐사선 등에 적용하여 우주 방사선 및 입자 검출 성능을 높이고 있습니다.\n",
      "- **의료 영상 및 생명과학**: MCP 기술이 의료용 이미징 장비, 특히 PET(양전자 방출 단층촬영) 및 형광 이미징 분야에 적용되어 해상도와 감도가 향상되고 있습니다.\n",
      "- **보안 및 산업 검사**: 고감도 광검출이 필요한 보안 스캐너, 비파괴 검사 장비에도 MCP 기술이 확대 적용되고 있습니다.\n",
      "\n",
      "### 4. 집적화 및 소형화\n",
      "- MCP와 관련 전자회로의 집적화가 진행되어, 소형화된 고성능 검출기 개발이 가능해졌습니다. 이는 휴대용 장비나 드론, 소형 위성 등에 탑재할 수 있는 MCP 기반 센서 개발로 이어지고 있습니다.\n",
      "\n",
      "---\n",
      "\n",
      "요약하자면, 최근 3년 간 MCP 분야는 소재 혁신, 제조 정밀도 향상, 성능 개선, 그리고 다양한 응용 분야 확대를 중심으로 빠르게 발전하고 있습니다. 특히 나노소재 적용과 고속·고감도 증폭 기술이 두드러진 특징입니다. 필요하시면 특정 응용 분야나 기술에 대해 더 자세히 설명드릴 수 있습니다.\n"
     ]
    }
   ],
   "source": [
    "for i in response:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95f62cd0",
   "metadata": {},
   "source": [
    "##### (2) 비동기(astream) 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b35c34ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_31956\\405798620.py:3: RuntimeWarning: coroutine 'RunnableSequence.ainvoke' was never awaited\n",
      "  async_answer = chain.ainvoke({'skill' : 'rag', 'year' : 3})\n",
      "RuntimeWarning: Enable tracemalloc to get the object allocation traceback\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<coroutine object RunnableSequence.ainvoke at 0x00000250371D38A0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ainvoke 출력\n",
    "\n",
    "async_answer = chain.ainvoke({'skill' : 'rag', 'year' : 3})\n",
    "async_answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "903d8663",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'최근 3년 간 RAG (Retrieval-Augmented Generation) 분야의 기술 발전은 매우 빠르게 진행되고 있으며, 주로 대규모 언어 모델과 정보 검색 기술의 결합을 통해 자연어 생성의 정확성과 신뢰성을 크게 향상시키는 데 초점이 맞춰져 있습니다. 주요 발전 내용을 정리하면 다음과 같습니다.\\n\\n1. **대규모 사전학습 언어모델과 검색기술의 통합 강화**  \\n   - GPT, BERT, T5 등 대형 언어 모델들이 RAG 프레임워크에 통합되어, 외부 지식베이스나 문서에서 실시간으로 정보를 검색하고 이를 바탕으로 더 정확한 답변을 생성하는 방식이 일반화되었습니다.  \\n   - Facebook AI Research(FAIR)에서 발표한 RAG 모델(2020년)은 최초로 검색과 생성 모델을 결합하여, 검색된 문서들을 조건으로 자연어를 생성하는 방식을 제안해 큰 주목을 받았습니다.\\n\\n2. **효율적인 검색 및 인덱싱 기법 발전**  \\n   - Dense retrieval(밀집 임베딩 기반 검색) 기술이 크게 발전하여, 기존의 키워드 기반 검색보다 더 의미론적으로 관련된 문서를 빠르게 찾아내는 것이 가능해졌습니다.  \\n   - FAISS, ANNOY, HNSW 등 효율적인 벡터 검색 라이브러리와 함께, 문서 임베딩을 실시간으로 업데이트하고 확장하는 기술들이 발전했습니다.\\n\\n3. **멀티모달 RAG 및 다양한 도메인 적용**  \\n   - 텍스트뿐만 아니라 이미지, 음성 등 다양한 데이터 유형을 결합한 멀티모달 RAG 연구가 진행되어, 예를 들어 이미지 설명 생성, 비디오 요약 등 다양한 분야에 적용되고 있습니다.  \\n   - 의료, 법률, 금융 등 전문 도메인에 특화된 RAG 시스템 개발도 활발히 이루어지고 있습니다.\\n\\n4. **지식 증강 및 사실 검증 강화**  \\n   - 생성된 텍스트의 신뢰성을 높이기 위해, 검색된 문서 기반의 사실 검증(fact-checking) 및 출처 표기 기술이 발전했습니다.  \\n   - RAG 모델이 생성하는 답변에 대해 근거 문서를 함께 제공하는 방식이 표준화되고 있습니다.\\n\\n5. **오픈소스 및 상용화 확대**  \\n   - Hugging Face, Meta AI 등에서 RAG 관련 오픈소스 라이브러리와 모델을 공개하여 연구 및 산업계에서 쉽게 활용할 수 있게 되었습니다.  \\n   - 구글, 마이크로소프트 등 대형 IT 기업들도 RAG 기술을 자사 검색엔진, 챗봇, 고객지원 시스템 등에 적극 도입하고 있습니다.\\n\\n요약하자면, 최근 3년간 RAG 분야는 대규모 언어 모델과 고도화된 검색 기술의 융합을 통해 자연어 생성의 정확도와 신뢰성을 크게 높였으며, 다양한 도메인과 멀티모달 데이터로 확장되고 있습니다. 또한, 오픈소스 생태계의 활성화와 상용화가 동시에 이루어지면서 실질적인 활용 사례가 급증하고 있습니다.'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = await async_answer\n",
    "result"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain-basic",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
